# COLEPA - Asistente Legal Gubernamental
# Backend FastAPI Mejorado para Consultas Legales Oficiales

import os
import re
import time
import logging
from datetime import datetime
from typing import List, Dict, Optional, Any

from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
import uvicorn

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Verificar y configurar OpenAI
try:
    from openai import OpenAI
    from dotenv import load_dotenv
    
    load_dotenv()
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    OPENAI_AVAILABLE = True
    logger.info("‚úÖ OpenAI configurado correctamente")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è OpenAI no disponible: {e}")
    OPENAI_AVAILABLE = False
    openai_client = None

# Importaciones locales con fallback
try:
    from app.vector_search import buscar_articulo_relevante, buscar_articulo_por_numero
    from app.prompt_builder import construir_prompt
    VECTOR_SEARCH_AVAILABLE = True
    logger.info("‚úÖ M√≥dulos de b√∫squeda vectorial cargados")
except ImportError:
    logger.warning("‚ö†Ô∏è M√≥dulos de b√∫squeda no encontrados, usando funciones mock")
    VECTOR_SEARCH_AVAILABLE = False
    
    def buscar_articulo_relevante(query_vector, collection_name):
        return {
            "pageContent": "Contenido de ejemplo del art√≠culo", 
            "nombre_ley": "C√≥digo Civil", 
            "numero_articulo": "123"
        }
    
    def buscar_articulo_por_numero(numero, collection_name):
        return {
            "pageContent": f"Contenido del art√≠culo {numero}", 
            "nombre_ley": "C√≥digo Civil", 
            "numero_articulo": str(numero)
        }
    
    def construir_prompt(contexto_legal, pregunta_usuario):
        return f"Contexto Legal: {contexto_legal}\n\nPregunta del Usuario: {pregunta_usuario}"

# ========== NUEVO: CLASIFICADOR INTELIGENTE ==========
try:
    from app.clasificador_inteligente import clasificar_y_procesar
    CLASIFICADOR_AVAILABLE = True
    logger.info("‚úÖ Clasificador inteligente cargado")
except ImportError:
    logger.warning("‚ö†Ô∏è Clasificador no encontrado, modo b√°sico")
    CLASIFICADOR_AVAILABLE = False
    
    def clasificar_y_procesar(texto):
        return {
            'tipo_consulta': 'consulta_legal',
            'respuesta_directa': None,
            'requiere_busqueda': True,
            'es_conversacional': False
        }

# === MODELOS PYDANTIC ===
class MensajeChat(BaseModel):
    role: str = Field(..., pattern="^(user|assistant|system)$")
    content: str = Field(..., min_length=1, max_length=3000)
    timestamp: Optional[datetime] = None

class ConsultaRequest(BaseModel):
    historial: List[MensajeChat] = Field(..., min_items=1, max_items=20)
    metadatos: Optional[Dict[str, Any]] = None

class FuenteLegal(BaseModel):
    ley: str
    articulo_numero: str
    libro: Optional[str] = None
    titulo: Optional[str] = None

class ConsultaResponse(BaseModel):
    respuesta: str
    fuente: Optional[FuenteLegal] = None
    recomendaciones: Optional[List[str]] = None
    tiempo_procesamiento: Optional[float] = None
    es_respuesta_oficial: bool = True

class StatusResponse(BaseModel):
    status: str
    timestamp: datetime
    version: str
    servicios: Dict[str, str]
    colecciones_disponibles: int

# === CONFIGURACI√ìN DEL SISTEMA - EXPANDIDO PARA 10 C√ìDIGOS ===
MAPA_COLECCIONES = {
    "C√≥digo Aduanero": "colepa_aduanero_maestro",  # ‚úÖ YA ACTIVO
    "C√≥digo Civil": "colepa_codigo_civil_maestro", 
    "C√≥digo de la Ni√±ez y la Adolescencia": "colepa_ninez_maestro",
    "C√≥digo de Organizaci√≥n Judicial": "colepa_organizacion_judicial_maestro",
    "C√≥digo Procesal Civil": "colepa_procesal_civil_maestro", 
    "C√≥digo Procesal Penal": "colepa_procesal_penal_maestro",
    "C√≥digo Laboral": "colepa_laboral_maestro",
    "C√≥digo Electoral": "colepa_electoral_maestro",
    "C√≥digo Penal": "colepa_penal_maestro",
    "C√≥digo Sanitario": "colepa_sanitario_maestro",
}

PALABRAS_CLAVE_EXPANDIDAS = {
    "C√≥digo Civil": [
        "civil", "matrimonio", "divorcio", "propiedad", "contratos", "familia", 
        "herencia", "sucesi√≥n", "sociedad conyugal", "bien ganancial", "patria potestad",
        "tutela", "curatela", "adopci√≥n", "filiaci√≥n", "alimentos", "r√©gimen patrimonial",
        "esposo", "esposa", "c√≥nyuge", "pareja", "hijos", "padres"
    ],
    "C√≥digo Penal": [
        "penal", "delito", "crimen", "pena", "prisi√≥n", "robo", "homicidio", "hurto",
        "estafa", "violaci√≥n", "agresi√≥n", "lesiones", "amenaza", "extorsi√≥n", "secuestro",
        "narcotr√°fico", "corrupci√≥n", "fraude", "violencia dom√©stica", "femicidio",
        "pega", "golpea", "golpes", "maltrato", "abuso", "acoso", "persigue", "molesta",
        "choque", "chocaron", "atropello", "accidente", "atropell√≥"
    ],
    "C√≥digo Laboral": [
        "laboral", "trabajo", "empleado", "salario", "vacaciones", "despido", "contrato laboral",
        "indemnizaci√≥n", "aguinaldo", "licencia", "maternidad", "seguridad social", "sindicato",
        "huelga", "jornada laboral", "horas extras", "jubilaci√≥n", "accidente laboral",
        "jefe", "patr√≥n", "empleador", "trabajador", "sueldo"
    ],
    "C√≥digo Procesal Civil": [
        "proceso civil", "demanda", "juicio civil", "sentencia", "apelaci√≥n", "recurso",
        "prueba", "testigo", "peritaje", "embargo", "medida cautelar", "ejecuci√≥n",
        "da√±os", "perjuicios", "responsabilidad civil", "indemnizaci√≥n"
    ],
    "C√≥digo Procesal Penal": [
        "proceso penal", "acusaci√≥n", "juicio penal", "fiscal", "defensor", "imputado",
        "querella", "investigaci√≥n", "allanamiento", "detenci√≥n", "prisi√≥n preventiva",
        "denuncia", "denunciar", "comisar√≠a", "polic√≠a"
    ],
    "C√≥digo Aduanero": [
        "aduana", "aduanero", "importaci√≥n", "exportaci√≥n", "aranceles", "tributo aduanero", "mercanc√≠a",
        "declaraci√≥n aduanera", "r√©gimen aduanero", "zona franca", "contrabando", "dep√≥sito", "habilitaci√≥n"
    ],
    "C√≥digo Electoral": [
        "electoral", "elecciones", "voto", "candidato", "sufragio", "padr√≥n electoral",
        "tribunal electoral", "campa√±a electoral", "partido pol√≠tico", "referendum"
    ],
    "C√≥digo de la Ni√±ez y la Adolescencia": [
        "menor", "ni√±o", "adolescente", "tutela", "adopci√≥n", "menor infractor",
        "protecci√≥n integral", "derechos del ni√±o", "consejer√≠a", "medida socioeducativa",
        "hijo", "hija", "ni√±os", "ni√±as", "menores"
    ],
    "C√≥digo de Organizaci√≥n Judicial": [
        "judicial", "tribunal", "juez", "competencia", "jurisdicci√≥n", "corte suprema",
        "juzgado", "fuero", "instancia", "sala", "magistrado", "secretario judicial"
    ],
    "C√≥digo Sanitario": [
        "sanitario", "salud", "medicina", "hospital", "cl√≠nica", "medicamento",
        "profesional sanitario", "epidemia", "vacuna", "control sanitario"
    ]
}

# === PROMPT MEJORADO PARA TEXTO EXACTO ===
INSTRUCCION_SISTEMA_LEGAL = """
Eres COLEPA, el asistente legal oficial especializado en legislaci√≥n paraguaya. Tu funci√≥n es proporcionar el texto exacto de las leyes sin a√±adir interpretaciones o recomendaciones adicionales.

REGLAS CR√çTICAS PARA RESPUESTAS:

1. **RESPUESTA DIRECTA INICIAL** (1-2 l√≠neas)
   - Responde la pregunta de forma directa y concisa
   - Ve directo al grano sin pre√°mbulos

2. **FUNDAMENTO LEGAL EXACTO** (obligatorio)
   - Proporciona el texto legal EXACTO como aparece en la ley
   - NO interpretes, NO parafrasees, USA EL TEXTO LITERAL
   - Cita claramente la ley y art√≠culo

3. **SIN ORIENTACI√ìN ADICIONAL** (cr√≠tico)
   - NO agregues pasos pr√°cticos
   - NO agregues recomendaciones  
   - NO agregues "consulte con un abogado"
   - NO agregues orientaci√≥n sobre d√≥nde acudir

ESTRUCTURA DE RESPUESTA:
- Respuesta directa (1-2 l√≠neas)
- Fundamento legal con texto exacto
- FIN (no agregar nada m√°s)

EJEMPLO CORRECTO:
Usuario: "¬øQu√© dice el art√≠culo 15 del c√≥digo aduanero?"

Respuesta:
"El art√≠culo 15 establece los casos de exenci√≥n de tributos aduaneros.

**Fundamento Legal:**
C√≥digo Aduanero, Art√≠culo 15: [TEXTO EXACTO DEL ART√çCULO COMO APARECE EN LA LEY]"

EJEMPLO INCORRECTO (NO hacer esto):
"El art√≠culo 15 establece... [interpretaci√≥n]
**Pasos a seguir:** [NO agregar esto]
**Recomendaciones:** [NO agregar esto]"

Usa √öNICAMENTE el texto proporcionado en el contexto legal. Si no tienes el texto exacto, di que no tienes acceso a esa disposici√≥n espec√≠fica.
"""

# === CONFIGURACI√ìN DE FASTAPI ===
app = FastAPI(
    title="COLEPA - Asistente Legal Oficial",
    description="Sistema de consultas legales basado en la legislaci√≥n paraguaya",
    version="3.2.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://www.colepa.com",
        "https://colepa.com", 
        "https://colepa-demo-2.vercel.app",
        "http://localhost:3000",
        "http://localhost:8080"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# === FUNCIONES AUXILIARES MEJORADAS ===
def extraer_numero_articulo_mejorado(texto: str) -> Optional[int]:
    """
    Extracci√≥n mejorada y m√°s precisa de n√∫meros de art√≠culo
    """
    texto_lower = texto.lower()
    
    # Patrones m√°s espec√≠ficos y completos
    patrones = [
        r'art[i√≠]culo\s*(?:n[√∫u]mero\s*)?(\d+)',
        r'art\.?\s*(\d+)',
        r'art√≠culo\s*(\d+)',
        r'articulo\s*(\d+)',
        r'art\s+(\d+)',
        r'(?:^|\s)(\d+)(?:\s|$)',  # N√∫mero solo si est√° aislado
    ]
    
    for patron in patrones:
        matches = re.finditer(patron, texto_lower)
        for match in matches:
            try:
                numero = int(match.group(1))
                if 1 <= numero <= 9999:  # Rango razonable para art√≠culos
                    logger.info(f"üîç N√∫mero de art√≠culo extra√≠do: {numero} con patr√≥n: {patron}")
                    return numero
            except (ValueError, IndexError):
                continue
    
    logger.info(f"üîç No se encontr√≥ n√∫mero de art√≠culo en: {texto[:50]}...")
    return None

def clasificar_consulta_inteligente(pregunta: str) -> str:
    """
    Clasificaci√≥n inteligente mejorada con mejor scoring
    """
    pregunta_lower = pregunta.lower()
    scores = {}
    
    # B√∫squeda por palabras clave con peso ajustado
    for ley, palabras in PALABRAS_CLAVE_EXPANDIDAS.items():
        score = 0
        for palabra in palabras:
            if palabra in pregunta_lower:
                # Mayor peso para coincidencias exactas de palabras completas
                if f" {palabra} " in f" {pregunta_lower} ":
                    score += 5
                elif palabra in pregunta_lower:
                    score += 2
        
        if score > 0:
            scores[ley] = score
    
    # B√∫squeda por menciones expl√≠citas de c√≥digos (peso muy alto)
    for ley in MAPA_COLECCIONES.keys():
        ley_lower = ley.lower()
        # Buscar nombre completo
        if ley_lower in pregunta_lower:
            scores[ley] = scores.get(ley, 0) + 20
        
        # Buscar versiones sin "c√≥digo"
        ley_sin_codigo = ley_lower.replace("c√≥digo ", "").replace("c√≥digo de ", "")
        if ley_sin_codigo in pregunta_lower:
            scores[ley] = scores.get(ley, 0) + 15
    
    # Patrones espec√≠ficos mejorados para casos reales
    patrones_especiales = {
        r'violen(cia|to|tar)|agre(si√≥n|dir)|golpe|maltrato|femicidio|pega|abuso': "C√≥digo Penal",
        r'matrimonio|divorcio|esposo|esposa|c√≥nyuge|familia|pareja': "C√≥digo Civil", 
        r'trabajo|empleo|empleado|jefe|patr√≥n|salario|sueldo|laboral': "C√≥digo Laboral",
        r'menor|ni√±o|ni√±a|adolescente|hijo|hija|adopci√≥n': "C√≥digo de la Ni√±ez y la Adolescencia",
        r'elecci√≥n|elecciones|voto|votar|candidato|pol√≠tico|electoral': "C√≥digo Electoral",
        r'choque|chocaron|atropello|atropell√≥|accidente|da√±os|perjuicios': "C√≥digo Procesal Civil",
        r'denuncia|fiscal|delito|acusado|penal|proceso penal|comisar√≠a': "C√≥digo Procesal Penal",
        r'aduana|aduanero|importa|exporta|mercanc√≠a|dep√≥sito': "C√≥digo Aduanero",
        r'salud|medicina|m√©dico|hospital|sanitario': "C√≥digo Sanitario",
        r'acoso|persigue|molesta|hostiga': "C√≥digo Penal"
    }
    
    for patron, ley in patrones_especiales.items():
        if re.search(patron, pregunta_lower):
            scores[ley] = scores.get(ley, 0) + 12
    
    # Determinar la mejor clasificaci√≥n
    if scores:
        mejor_ley = max(scores.keys(), key=lambda k: scores[k])
        score_final = scores[mejor_ley]
        logger.info(f"üìö Consulta clasificada como: {mejor_ley} (score: {score_final})")
        return MAPA_COLECCIONES[mejor_ley]
    
    # Default: C√≥digo Civil (m√°s general)
    logger.info("üìö Consulta no clasificada espec√≠ficamente, usando C√≥digo Civil por defecto")
    return MAPA_COLECCIONES["C√≥digo Civil"]

def clasificar_consulta_con_ia_robusta(pregunta: str) -> str:
    """
    S√öPER ENRUTADOR: Clasificaci√≥n robusta usando IA especializada
    """
    if not OPENAI_AVAILABLE or not openai_client:
        logger.warning("‚ö†Ô∏è OpenAI no disponible, usando clasificaci√≥n b√°sica")
        return clasificar_consulta_inteligente(pregunta)
    
    # PROMPT ESPECIALIZADO PARA CLASIFICACI√ìN
    prompt_clasificacion = f"""
Eres un experto clasificador de consultas legales paraguayas. Tu √∫nica tarea es identificar a qu√© C√ìDIGO LEGAL pertenece la siguiente consulta.

C√ìDIGOS DISPONIBLES:
1. C√≥digo Civil - matrimonio, divorcio, familia, propiedad, contratos, herencia, adopci√≥n, tutela, bienes
2. C√≥digo Penal - delitos, cr√≠menes, violencia, agresi√≥n, robo, homicidio, maltrato, femicidio, drogas
3. C√≥digo Laboral - trabajo, empleo, salarios, despidos, vacaciones, derechos laborales, sindicatos
4. C√≥digo Procesal Civil - demandas civiles, juicios civiles, da√±os y perjuicios, procedimientos civiles
5. C√≥digo Procesal Penal - denuncias penales, procesos penales, investigaciones, fiscal√≠a
6. C√≥digo Aduanero - aduana, importaci√≥n, exportaci√≥n, mercanc√≠as, aranceles, dep√≥sitos, contrabando
7. C√≥digo Electoral - elecciones, votos, candidatos, partidos pol√≠ticos, procesos electorales
8. C√≥digo de la Ni√±ez y la Adolescencia - menores, ni√±os, adolescentes, tutela de menores, adopci√≥n
9. C√≥digo de Organizaci√≥n Judicial - tribunales, jueces, competencias judiciales, organizaci√≥n courts
10. C√≥digo Sanitario - salud, medicina, hospitales, medicamentos, control sanitario

CONSULTA A CLASIFICAR: "{pregunta}"

C√ìDIGO IDENTIFICADO:"""

    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt_clasificacion}],
            temperature=0.1,
            max_tokens=50
        )
        
        codigo_identificado = response.choices[0].message.content.strip()
        
        # Mapear respuesta a colecci√≥n
        if codigo_identificado in MAPA_COLECCIONES:
            collection_name = MAPA_COLECCIONES[codigo_identificado]
            logger.info(f"üéØ IA clasific√≥ correctamente: {codigo_identificado} ‚Üí {collection_name}")
            return collection_name
        else:
            # Fuzzy matching para nombres similares
            for codigo_oficial in MAPA_COLECCIONES.keys():
                if any(word in codigo_identificado.lower() for word in codigo_oficial.lower().split()):
                    collection_name = MAPA_COLECCIONES[codigo_oficial]
                    logger.info(f"üéØ IA clasific√≥ (fuzzy match): {codigo_identificado} ‚Üí {codigo_oficial}")
                    return collection_name
            
            # Fallback
            logger.warning(f"‚ö†Ô∏è IA devolvi√≥ c√≥digo no reconocido: {codigo_identificado}")
            return clasificar_consulta_inteligente(pregunta)
            
    except Exception as e:
        logger.error(f"‚ùå Error en clasificaci√≥n con IA: {e}")
        return clasificar_consulta_inteligente(pregunta)

def generar_respuesta_legal(historial: List[MensajeChat], contexto: Optional[Dict] = None) -> str:
    """
    Generaci√≥n de respuesta legal mejorada - TEXTO EXACTO √öNICAMENTE
    """
    if not OPENAI_AVAILABLE or not openai_client:
        return generar_respuesta_con_contexto(historial[-1].content, contexto)
    
    try:
        # Preparar mensajes para OpenAI
        mensajes = [{"role": "system", "content": INSTRUCCION_SISTEMA_LEGAL}]
        
        # Agregar contexto legal si existe - USANDO PROMPT_BUILDER
        if contexto and contexto.get("pageContent"):
            contexto_legal_texto = contexto.get('pageContent', '')
            prompt_construido = construir_prompt(contexto_legal_texto, historial[-1].content)
            
            mensajes.append({"role": "user", "content": prompt_construido})
            logger.info(f"üìñ Usando prompt_builder.py para contexto: {contexto.get('nombre_ley')} Art. {contexto.get('numero_articulo')}")
        else:
            # Sin contexto espec√≠fico
            for msg in historial[-2:]:
                role = "assistant" if msg.role == "assistant" else "user"
                mensajes.append({"role": role, "content": msg.content})
        
        # Llamada a OpenAI con par√°metros optimizados para TEXTO EXACTO
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=mensajes,
            temperature=0.0,  # COMPLETAMENTE CONSERVADOR - SIN CREATIVIDAD
            max_tokens=1000,  # REDUCIDO - Solo texto exacto
            presence_penalty=0,
            frequency_penalty=0
        )
        
        respuesta = response.choices[0].message.content
        logger.info("‚úÖ Respuesta generada con OpenAI - Modo texto exacto")
        
        return respuesta
        
    except Exception as e:
        logger.error(f"‚ùå Error con OpenAI: {e}")
        return generar_respuesta_con_contexto(historial[-1].content, contexto)

def generar_respuesta_con_contexto(pregunta: str, contexto: Optional[Dict] = None) -> str:
    """
    Respuesta directa usando √öNICAMENTE el contexto de Qdrant - SIN ORIENTACI√ìN ADICIONAL
    """
    if contexto and contexto.get("pageContent"):
        ley = contexto.get('nombre_ley', 'Legislaci√≥n paraguaya')
        articulo = contexto.get('numero_articulo', 'N/A')
        contenido = contexto.get('pageContent', '')
        
        # RESPUESTA SIMPLE - SOLO TEXTO EXACTO
        response = f"""**{ley} - Art√≠culo {articulo}**

{contenido}

*Fuente: {ley}, Art√≠culo {articulo}*"""
        
        logger.info(f"‚úÖ Respuesta generada con contexto exacto: {ley} Art. {articulo}")
        return response
    else:
        return f"""**Consulta Legal**

No encontr√© esa disposici√≥n espec√≠fica en mi base de datos legal para: "{pregunta}"

*¬øPuede reformular su consulta con m√°s detalles espec√≠ficos?*"""

def extraer_fuente_legal(contexto: Optional[Dict]) -> Optional[FuenteLegal]:
    """
    Extrae informaci√≥n de la fuente legal del contexto
    """
    if not contexto:
        return None
    
    return FuenteLegal(
        ley=contexto.get("nombre_ley", "No especificada"),
        articulo_numero=str(contexto.get("numero_articulo", "N/A")),
        libro=contexto.get("libro"),
        titulo=contexto.get("titulo")
    )

# === MIDDLEWARE ===
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    client_ip = request.client.host
    logger.info(f"üì• {request.method} {request.url.path} - IP: {client_ip}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(f"üì§ {response.status_code} - {process_time:.2f}s")
    
    return response

# === ENDPOINTS ===
@app.get("/", response_model=StatusResponse)
async def sistema_status():
    """Estado del sistema COLEPA"""
    return StatusResponse(
        status="‚úÖ Sistema COLEPA Operativo",
        timestamp=datetime.now(),
        version="3.2.0",
        servicios={
            "openai": "disponible" if OPENAI_AVAILABLE else "no disponible",
            "busqueda_vectorial": "disponible" if VECTOR_SEARCH_AVAILABLE else "modo_demo",
            "base_legal": "legislaci√≥n paraguaya completa"
        },
        colecciones_disponibles=len(MAPA_COLECCIONES)
    )

@app.get("/api/health")
async def health_check():
    """Verificaci√≥n de salud detallada"""
    health_status = {
        "sistema": "operativo",
        "timestamp": datetime.now().isoformat(),
        "version": "3.2.0",
        "servicios": {
            "openai": "‚ùå no disponible",
            "qdrant": "‚ùå no disponible" if not VECTOR_SEARCH_AVAILABLE else "‚úÖ operativo",
            "base_legal": "‚úÖ cargada"
        }
    }
    
    if OPENAI_AVAILABLE and openai_client:
        try:
            openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            health_status["servicios"]["openai"] = "‚úÖ operativo"
        except Exception as e:
            health_status["servicios"]["openai"] = f"‚ùå error: {str(e)[:50]}"
    
    return health_status

@app.get("/api/codigos")
async def listar_codigos_legales():
    """Lista todos los c√≥digos legales disponibles"""
    return {
        "codigos_disponibles": list(MAPA_COLECCIONES.keys()),
        "total_codigos": len(MAPA_COLECCIONES),
        "descripcion": "C√≥digos legales completos de la Rep√∫blica del Paraguay",
        "ultima_actualizacion": "2024",
        "cobertura": "Legislaci√≥n nacional vigente"
    }

# ========== ENDPOINT PRINCIPAL MODIFICADO PARA TEXTO EXACTO ==========
@app.post("/api/consulta", response_model=ConsultaResponse)
async def procesar_consulta_legal(
    request: ConsultaRequest, 
    background_tasks: BackgroundTasks
):
    """
    Endpoint principal para consultas legales oficiales - TEXTO EXACTO √öNICAMENTE
    """
    start_time = time.time()
    
    try:
        historial = request.historial
        pregunta_actual = historial[-1].content
        
        # L√≠mite de historial para evitar error 422
        MAX_HISTORIAL = 6
        if len(historial) > MAX_HISTORIAL:
            historial_limitado = historial[-MAX_HISTORIAL:]
            logger.info(f"‚ö†Ô∏è Historial limitado a {len(historial_limitado)} mensajes")
        else:
            historial_limitado = historial
        
        logger.info(f"üîç Nueva consulta legal: {pregunta_actual[:100]}...")
        
        # Clasificaci√≥n inteligente (si est√° disponible)
        if CLASIFICADOR_AVAILABLE:
            logger.info("üß† Iniciando clasificaci√≥n inteligente...")
            clasificacion = clasificar_y_procesar(pregunta_actual)
            
            # Manejo de consultas conversacionales
            if clasificacion['es_conversacional'] and clasificacion['respuesta_directa']:
                logger.info("üí¨ Generando respuesta conversacional directa...")
                tiempo_procesamiento = time.time() - start_time
                
                return ConsultaResponse(
                    respuesta=clasificacion['respuesta_directa'],
                    fuente=None,
                    recomendaciones=None,  # SIN RECOMENDACIONES AUTOM√ÅTICAS
                    tiempo_procesamiento=round(tiempo_procesamiento, 2),
                    es_respuesta_oficial=True
                )
            
            # Manejo de consultas no legales
            if not clasificacion['requiere_busqueda']:
                logger.info("üö´ Consulta no legal, redirigiendo...")
                tiempo_procesamiento = time.time() - start_time
                
                return ConsultaResponse(
                    respuesta=clasificacion['respuesta_directa'] or 
                             "Me especializo √∫nicamente en consultas sobre las leyes de Paraguay. "
                             "¬øHay alguna pregunta legal en la que pueda asistirte?",
                    fuente=None,
                    recomendaciones=None,  # SIN RECOMENDACIONES AUTOM√ÅTICAS
                    tiempo_procesamiento=round(tiempo_procesamiento, 2),
                    es_respuesta_oficial=True
                )
        
        # Clasificar la consulta legal
        collection_name = clasificar_consulta_con_ia_robusta(pregunta_actual)
        logger.info(f"üìö C√≥digo legal identificado: {collection_name}")
        
        # Buscar informaci√≥n legal relevante
        contexto = None
        numero_articulo = extraer_numero_articulo_mejorado(pregunta_actual)
        
        if VECTOR_SEARCH_AVAILABLE:
            try:
                if numero_articulo:
                    # B√∫squeda por n√∫mero exacto
                    logger.info(f"üéØ Buscando art√≠culo espec√≠fico: {numero_articulo} en {collection_name}")
                    contexto = buscar_articulo_por_numero(numero_articulo, collection_name)
                    
                    if contexto and contexto.get("pageContent"):
                        logger.info(f"‚úÖ Art√≠culo {numero_articulo} encontrado por b√∫squeda exacta")
                    else:
                        logger.warning(f"‚ùå Art√≠culo {numero_articulo} no encontrado por b√∫squeda exacta")
                        
                        # FALLBACK: B√∫squeda sem√°ntica con n√∫mero en el texto
                        if OPENAI_AVAILABLE:
                            logger.info(f"üîÑ Intentando b√∫squeda sem√°ntica para art√≠culo {numero_articulo}")
                            
                            consulta_semantica = f"art√≠culo {numero_articulo} c√≥digo penal civil procesal laboral"
                            
                            embedding_response = openai_client.embeddings.create(
                                model="text-embedding-ada-002",
                                input=consulta_semantica
                            )
                            query_vector = embedding_response.data[0].embedding
                            
                            contexto_semantico = buscar_articulo_relevante(query_vector, collection_name)
                            
                            if (contexto_semantico and 
                                contexto_semantico.get("pageContent") and 
                                str(numero_articulo) in contexto_semantico.get("pageContent", "")):
                                
                                contexto = contexto_semantico
                                logger.info(f"‚úÖ Art√≠culo {numero_articulo} encontrado por b√∫squeda sem√°ntica")
                            else:
                                logger.warning(f"‚ùå B√∫squeda sem√°ntica no encontr√≥ art√≠culo {numero_articulo}")
                                contexto = None
                
                # B√∫squeda sem√°ntica general si no se busc√≥ por n√∫mero o no se encontr√≥
                if not contexto or not contexto.get("pageContent"):
                    logger.info(f"üîé Realizando b√∫squeda sem√°ntica general en {collection_name}")
                    
                    if OPENAI_AVAILABLE:
                        embedding_response = openai_client.embeddings.create(
                            model="text-embedding-ada-002",
                            input=pregunta_actual
                        )
                        query_vector = embedding_response.data[0].embedding
                        contexto = buscar_articulo_relevante(query_vector, collection_name)
                        
                        if contexto and contexto.get("pageContent"):
                            logger.info("‚úÖ Contexto encontrado por b√∫squeda sem√°ntica general")
                        else:
                            logger.warning("‚ùå No se encontr√≥ contexto por b√∫squeda sem√°ntica")
                    else:
                        # Fallback sin OpenAI
                        contexto = buscar_articulo_relevante([], collection_name)
                        
            except Exception as e:
                logger.error(f"‚ùå Error en b√∫squeda vectorial: {e}")
                contexto = None

        # Validar contexto final
        if contexto and isinstance(contexto, dict) and contexto.get("pageContent"):
            logger.info(f"üìñ Contexto legal final:")
            logger.info(f"   - Ley: {contexto.get('nombre_ley', 'N/A')}")
            logger.info(f"   - Art√≠culo: {contexto.get('numero_articulo', 'N/A')}")
            logger.info(f"   - Contenido: {contexto.get('pageContent', '')[:200]}...")
        else:
            logger.warning("‚ùå No se encontr√≥ contexto legal relevante para la consulta")
            contexto = None
        
        # Generar respuesta legal - SOLO TEXTO EXACTO
        respuesta = generar_respuesta_legal(historial_limitado, contexto)
        
        # Preparar respuesta estructurada - SIN RECOMENDACIONES AUTOM√ÅTICAS
        tiempo_procesamiento = time.time() - start_time
        fuente = extraer_fuente_legal(contexto)
        
        # NO GENERAR RECOMENDACIONES AUTOM√ÅTICAS - ELIMINADO COMPLETAMENTE
        recomendaciones = None  # SIEMPRE None - Sin orientaci√≥n autom√°tica
        
        response_data = ConsultaResponse(
            respuesta=respuesta,
            fuente=fuente,
            recomendaciones=recomendaciones,  # SIEMPRE None
            tiempo_procesamiento=round(tiempo_procesamiento, 2),
            es_respuesta_oficial=True
        )
        
        logger.info(f"‚úÖ Consulta procesada exitosamente en {tiempo_procesamiento:.2f}s")
        if CLASIFICADOR_AVAILABLE and 'clasificacion' in locals():
            logger.info(f"üè∑Ô∏è Tipo clasificado: {clasificacion.get('tipo_consulta', 'N/A')}")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå Error procesando consulta: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Error interno del sistema",
                "mensaje": "No fue posible procesar su consulta en este momento",
                "recomendacion": "Intente nuevamente en unos momentos",
                "codigo_error": str(e)[:100]
            }
        )

# === MANEJO DE ERRORES ===
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": True,
            "status_code": exc.status_code,
            "detalle": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "mensaje_usuario": "Ha ocurrido un error procesando su consulta"
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"‚ùå Error no controlado: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": True,
            "status_code": 500,
            "detalle": "Error interno del servidor",
            "timestamp": datetime.now().isoformat(),
            "mensaje_usuario": "El sistema est√° experimentando dificultades t√©cnicas"
        }
    )

# === PUNTO DE ENTRADA ===
if __name__ == "__main__":
    logger.info("üöÄ Iniciando COLEPA - Sistema Legal Gubernamental v3.2.0")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=int(os.getenv("PORT", 8000)),
        reload=False,
        log_level="info"
    )
