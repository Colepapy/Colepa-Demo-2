# COLEPA - Asistente Legal Gubernamental
# Backend FastAPI Mejorado para Consultas Legales Oficiales

import os
import re
import time
import logging
from datetime import datetime
from typing import List, Dict, Optional, Any

from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
import uvicorn

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Verificar y configurar OpenAI
try:
    from openai import OpenAI
    from dotenv import load_dotenv
    
    load_dotenv()
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    OPENAI_AVAILABLE = True
    logger.info("‚úÖ OpenAI configurado correctamente")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è OpenAI no disponible: {e}")
    OPENAI_AVAILABLE = False
    openai_client = None

# Importaciones locales con fallback
try:
    from app.vector_search import buscar_articulo_relevante, buscar_articulo_por_numero
    from app.prompt_builder import construir_prompt
    VECTOR_SEARCH_AVAILABLE = True
    logger.info("‚úÖ M√≥dulos de b√∫squeda vectorial cargados")
except ImportError:
    logger.warning("‚ö†Ô∏è M√≥dulos de b√∫squeda no encontrados, usando funciones mock")
    VECTOR_SEARCH_AVAILABLE = False
    
    def buscar_articulo_relevante(query_vector, collection_name):
        return {
            "pageContent": "Contenido de ejemplo del art√≠culo", 
            "nombre_ley": "C√≥digo Civil", 
            "numero_articulo": "123"
        }
    
    def buscar_articulo_por_numero(numero, collection_name):
        return {
            "pageContent": f"Contenido del art√≠culo {numero}", 
            "nombre_ley": "C√≥digo Civil", 
            "numero_articulo": str(numero)
        }
    
    def construir_prompt(contexto_legal, pregunta_usuario):
        return f"Contexto Legal: {contexto_legal}\n\nPregunta del Usuario: {pregunta_usuario}"

# ========== NUEVO: CLASIFICADOR INTELIGENTE ==========
try:
    from app.clasificador_inteligente import clasificar_y_procesar
    CLASIFICADOR_AVAILABLE = True
    logger.info("‚úÖ Clasificador inteligente cargado")
except ImportError:
    logger.warning("‚ö†Ô∏è Clasificador no encontrado, modo b√°sico")
    CLASIFICADOR_AVAILABLE = False
    
    def clasificar_y_procesar(texto):
        return {
            'tipo_consulta': 'consulta_legal',
            'respuesta_directa': None,
            'requiere_busqueda': True,
            'es_conversacional': False
        }

# === MODELOS PYDANTIC ===
class MensajeChat(BaseModel):
    role: str = Field(..., pattern="^(user|assistant|system)$")
    content: str = Field(..., min_length=1, max_length=3000)
    timestamp: Optional[datetime] = None

class ConsultaRequest(BaseModel):
    historial: List[MensajeChat] = Field(..., min_items=1, max_items=20)
    metadatos: Optional[Dict[str, Any]] = None

class FuenteLegal(BaseModel):
    ley: str
    articulo_numero: str
    libro: Optional[str] = None
    titulo: Optional[str] = None

class ConsultaResponse(BaseModel):
    respuesta: str
    fuente: Optional[FuenteLegal] = None
    recomendaciones: Optional[List[str]] = None
    tiempo_procesamiento: Optional[float] = None
    es_respuesta_oficial: bool = True

class StatusResponse(BaseModel):
    status: str
    timestamp: datetime
    version: str
    servicios: Dict[str, str]
    colecciones_disponibles: int

# === CONFIGURACI√ìN DEL SISTEMA ===
MAPA_COLECCIONES = {
   "aduanero": "colepa_aduanero_maestro",
    "civil": "colepa_civil_maestro", 
    "electoral": "colepa_electoral_maestro",
    "laboral": "colepa_laboral_maestro",
    "ninezadolescencia": "colepa_ninezadolescencia_maestro",
    "organizacion_judicial": "colepa_organizacion_judicial_maestro",
    "penal": "colepa_penal_maestro",
    "procesal_civil": "colepa_procesal_civil_maestro",
    "procesal_penal": "colepa_procesal_penal_maestro",
    "sanitario": "colepa_sanitario_maestro"
}

PALABRAS_CLAVE_EXPANDIDAS = {
    "C√≥digo Civil": [
        "civil", "matrimonio", "divorcio", "propiedad", "contratos", "familia", 
        "herencia", "sucesi√≥n", "sociedad conyugal", "bien ganancial", "patria potestad",
        "tutela", "curatela", "adopci√≥n", "filiaci√≥n", "alimentos", "r√©gimen patrimonial",
        "esposo", "esposa", "c√≥nyuge", "pareja", "hijos", "padres"
    ],
    "C√≥digo Penal": [
        "penal", "delito", "crimen", "pena", "prisi√≥n", "robo", "homicidio", "hurto",
        "estafa", "violaci√≥n", "agresi√≥n", "lesiones", "amenaza", "extorsi√≥n", "secuestro",
        "narcotr√°fico", "corrupci√≥n", "fraude", "violencia dom√©stica", "femicidio",
        "pega", "golpea", "golpes", "maltrato", "abuso", "acoso", "persigue", "molesta",
        "choque", "chocaron", "atropello", "accidente", "atropell√≥"
    ],
    "C√≥digo Laboral": [
        "laboral", "trabajo", "empleado", "salario", "vacaciones", "despido", "contrato laboral",
        "indemnizaci√≥n", "aguinaldo", "licencia", "maternidad", "seguridad social", "sindicato",
        "huelga", "jornada laboral", "horas extras", "jubilaci√≥n", "accidente laboral",
        "jefe", "patr√≥n", "empleador", "trabajador", "sueldo"
    ],
    "C√≥digo Procesal Civil": [
        "proceso civil", "demanda", "juicio civil", "sentencia", "apelaci√≥n", "recurso",
        "prueba", "testigo", "peritaje", "embargo", "medida cautelar", "ejecuci√≥n",
        "da√±os", "perjuicios", "responsabilidad civil", "indemnizaci√≥n"
    ],
    "C√≥digo Procesal Penal": [
        "proceso penal", "acusaci√≥n", "juicio penal", "fiscal", "defensor", "imputado",
        "querella", "investigaci√≥n", "allanamiento", "detenci√≥n", "prisi√≥n preventiva",
        "denuncia", "denunciar", "comisar√≠a", "polic√≠a"
    ],
    "C√≥digo Aduanero": [
        "aduana", "aduanero", "importaci√≥n", "exportaci√≥n", "aranceles", "tributo aduanero", "mercanc√≠a",
        "declaraci√≥n aduanera", "r√©gimen aduanero", "zona franca", "contrabando", "dep√≥sito", "habilitaci√≥n"
    ],
    "C√≥digo Electoral": [
        "electoral", "elecciones", "voto", "candidato", "sufragio", "padr√≥n electoral",
        "tribunal electoral", "campa√±a electoral", "partido pol√≠tico", "referendum"
    ],
    "C√≥digo de la Ni√±ez y la Adolescencia": [
        "menor", "ni√±o", "adolescente", "tutela", "adopci√≥n", "menor infractor",
        "protecci√≥n integral", "derechos del ni√±o", "consejer√≠a", "medida socioeducativa",
        "hijo", "hija", "ni√±os", "ni√±as", "menores"
    ],
    "C√≥digo de Organizaci√≥n Judicial": [
        "judicial", "tribunal", "juez", "competencia", "jurisdicci√≥n", "corte suprema",
        "juzgado", "fuero", "instancia", "sala", "magistrado", "secretario judicial"
    ],
    "C√≥digo Sanitario": [
        "sanitario", "salud", "medicina", "hospital", "cl√≠nica", "medicamento",
        "profesional sanitario", "epidemia", "vacuna", "control sanitario"
    ]
}

# === PROMPT SIMPLIFICADO PARA TEXTO EXACTO ===
INSTRUCCION_SISTEMA_LEGAL = """
Eres COLEPA, el asistente legal oficial especializado en legislaci√≥n paraguaya. 

INSTRUCCIONES CR√çTICAS:
1. **RESPUESTA DIRECTA INICIAL** (1-2 l√≠neas)
   - Explica brevemente qu√© establece el art√≠culo

2. **FUNDAMENTO LEGAL** (obligatorio)
   - Usa EXACTAMENTE el texto legal proporcionado
   - NO parafrasees, NO interpretes, USA EL TEXTO LITERAL
   - Cita claramente la ley y art√≠culo

3. **NO AGREGUES:**
   - NO orientaci√≥n pr√°ctica
   - NO recomendaciones  
   - NO pasos a seguir
   - NO "consulte con un abogado"

FORMATO:
[Explicaci√≥n breve]

**Fundamento Legal:**
[TEXTO EXACTO DEL CONTEXTO]

FIN.

Usa √öNICAMENTE el texto proporcionado en el contexto legal.
"""

# === CONFIGURACI√ìN DE FASTAPI ===
app = FastAPI(
    title="COLEPA - Asistente Legal Oficial",
    description="Sistema de consultas legales basado en la legislaci√≥n paraguaya",
    version="3.1.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://www.colepa.com",
        "https://colepa.com", 
        "https://colepa-demo-2.vercel.app",
        "http://localhost:3000",
        "http://localhost:8080"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# === FUNCIONES AUXILIARES MEJORADAS ===
def extraer_numero_articulo_mejorado(texto: str) -> Optional[int]:
    """
    Extracci√≥n mejorada y m√°s precisa de n√∫meros de art√≠culo
    """
    texto_lower = texto.lower()
    
    # Patrones m√°s espec√≠ficos y completos
    patrones = [
        r'art[i√≠]culo\s*(?:n[√∫u]mero\s*)?(\d+)',
        r'art\.?\s*(\d+)',
        r'art√≠culo\s*(\d+)',
        r'articulo\s*(\d+)',
        r'art\s+(\d+)',
        r'(?:^|\s)(\d+)(?:\s|$)',  # N√∫mero solo si est√° aislado
    ]
    
    for patron in patrones:
        matches = re.finditer(patron, texto_lower)
        for match in matches:
            try:
                numero = int(match.group(1))
                if 1 <= numero <= 9999:  # Rango razonable para art√≠culos
                    logger.info(f"üîç N√∫mero de art√≠culo extra√≠do: {numero} con patr√≥n: {patron}")
                    return numero
            except (ValueError, IndexError):
                continue
    
    logger.info(f"üîç No se encontr√≥ n√∫mero de art√≠culo en: {texto[:50]}...")
    return None

def clasificar_consulta_inteligente(pregunta: str) -> str:
    """
    Clasificaci√≥n inteligente mejorada con mejor scoring
    """
    pregunta_lower = pregunta.lower()
    scores = {}
    
    # B√∫squeda por palabras clave con peso ajustado
    for ley, palabras in PALABRAS_CLAVE_EXPANDIDAS.items():
        score = 0
        for palabra in palabras:
            if palabra in pregunta_lower:
                # Mayor peso para coincidencias exactas de palabras completas
                if f" {palabra} " in f" {pregunta_lower} ":
                    score += 5
                elif palabra in pregunta_lower:
                    score += 2
        
        if score > 0:
            scores[ley] = score
    
    # B√∫squeda por menciones expl√≠citas de c√≥digos (peso muy alto)
    for ley in MAPA_COLECCIONES.keys():
        ley_lower = ley.lower()
        # Buscar nombre completo
        if ley_lower in pregunta_lower:
            scores[ley] = scores.get(ley, 0) + 20
        
        # Buscar versiones sin "c√≥digo"
        ley_sin_codigo = ley_lower.replace("c√≥digo ", "").replace("c√≥digo de ", "")
        if ley_sin_codigo in pregunta_lower:
            scores[ley] = scores.get(ley, 0) + 15
    
    # Patrones espec√≠ficos mejorados para casos reales
    patrones_especiales = {
        r'violen(cia|to|tar)|agre(si√≥n|dir)|golpe|maltrato|femicidio|pega|abuso': "C√≥digo Penal",
        r'matrimonio|divorcio|esposo|esposa|c√≥nyuge|familia|pareja': "C√≥digo Civil", 
        r'trabajo|empleo|empleado|jefe|patr√≥n|salario|sueldo|laboral': "C√≥digo Laboral",
        r'menor|ni√±o|ni√±a|adolescente|hijo|hija|adopci√≥n': "C√≥digo de la Ni√±ez y la Adolescencia",
        r'elecci√≥n|elecciones|voto|votar|candidato|pol√≠tico|electoral': "C√≥digo Electoral",
        r'choque|chocaron|atropello|atropell√≥|accidente|da√±os|perjuicios': "C√≥digo Procesal Civil",
        r'denuncia|fiscal|delito|acusado|penal|proceso penal|comisar√≠a': "C√≥digo Procesal Penal",
        r'aduana|aduanero|importa|exporta|mercanc√≠a|dep√≥sito': "C√≥digo Aduanero",
        r'salud|medicina|m√©dico|hospital|sanitario': "C√≥digo Sanitario",
        r'acoso|persigue|molesta|hostiga': "C√≥digo Penal"
    }
    
    for patron, ley in patrones_especiales.items():
        if re.search(patron, pregunta_lower):
            scores[ley] = scores.get(ley, 0) + 12
    
    # Determinar la mejor clasificaci√≥n
    if scores:
        mejor_ley = max(scores.keys(), key=lambda k: scores[k])
        score_final = scores[mejor_ley]
        logger.info(f"üìö Consulta clasificada como: {mejor_ley} (score: {score_final})")
        return MAPA_COLECCIONES[mejor_ley]
    
    # Default: C√≥digo Civil (m√°s general)
    logger.info("üìö Consulta no clasificada espec√≠ficamente, usando C√≥digo Civil por defecto")
    return MAPA_COLECCIONES["civil"]

def clasificar_consulta_con_ia_robusta(pregunta: str) -> str:
    """
    S√öPER ENRUTADOR: Clasificaci√≥n robusta usando IA especializada
    FIX: Prompt ultra-corto y timeout para evitar error 500
    """
    if not OPENAI_AVAILABLE or not openai_client:
        logger.warning("‚ö†Ô∏è OpenAI no disponible, usando clasificaci√≥n b√°sica")
        return clasificar_consulta_inteligente(pregunta)
    
    try:
        # LOG SEGURO PARA DIAGN√ìSTICO
        print(f"üß† INICIO clasificar_consulta_con_ia_robusta")
        print(f"üìù Pregunta recibida: {pregunta[:100]}...")
        
        # PROMPT ULTRA-CORTO PARA EVITAR TIMEOUT
        prompt_ultra_corto = f"""
        Consulta: {pregunta[:150]}
        
        Responde solo con uno de estos c√≥digos exactos:
        - C√≥digo Civil
        - C√≥digo Penal  
        - C√≥digo Laboral
        - C√≥digo Procesal Civil
        - C√≥digo Procesal Penal
        - C√≥digo Aduanero
        - C√≥digo Electoral
        - C√≥digo de la Ni√±ez y la Adolescencia
        - C√≥digo de Organizaci√≥n Judicial
        - C√≥digo Sanitario
        
        C√≥digo:"""
        
        print("üîó Llamando a OpenAI con prompt ultra-corto...")
        
        # LLAMADA CON TIMEOUT Y PAR√ÅMETROS M√çNIMOS
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",  # Modelo m√°s r√°pido
            messages=[{"role": "user", "content": prompt_ultra_corto}],
            temperature=0,  # Sin creatividad
            max_tokens=20,  # M√°ximo ultra-bajo
            timeout=15  # Timeout de 15 segundos
        )
        
        codigo_identificado = response.choices[0].message.content.strip()
        print(f"‚úÖ OpenAI respondi√≥: {codigo_identificado}")
        
        # Mapear respuesta a colecci√≥n
        if codigo_identificado in MAPA_COLECCIONES:
            collection_name = MAPA_COLECCIONES[codigo_identificado]
            print(f"üéØ Mapeado exitosamente: {codigo_identificado} ‚Üí {collection_name}")
            return collection_name
        else:
            # Fuzzy matching mejorado
            for codigo_oficial in MAPA_COLECCIONES.keys():
                if any(word in codigo_identificado.lower() for word in codigo_oficial.lower().split()):
                    collection_name = MAPA_COLECCIONES[codigo_oficial]
                    print(f"üéØ Mapeado fuzzy: {codigo_identificado} ‚Üí {codigo_oficial}")
                    return collection_name
            
            # Fallback seguro
            print(f"‚ö†Ô∏è C√≥digo no reconocido: {codigo_identificado}, usando fallback")
            return clasificar_consulta_inteligente(pregunta)
            
    except Exception as e:
        print(f"üö® ERROR en clasificar_consulta_con_ia_robusta: {type(e).__name__}: {str(e)}")
        print("üîÑ Usando clasificaci√≥n b√°sica como fallback")
        return clasificar_consulta_inteligente(pregunta)

async def buscar_con_manejo_errores(numero_articulo, pregunta_actual, collection_name):
    """
    Funci√≥n auxiliar para b√∫squeda con manejo robusto de errores Qdrant
    """
    contexto = None
    
    try:
        print(f"üîé INICIO b√∫squeda - Art√≠culo: {numero_articulo}, Colecci√≥n: {collection_name}")
        
        if numero_articulo:
            # B√öSQUEDA POR N√öMERO EXACTO CON TIMEOUT
            print(f"üéØ Buscando art√≠culo espec√≠fico: {numero_articulo}")
            try:
                contexto = buscar_articulo_por_numero(numero_articulo, collection_name)
                print(f"‚úÖ B√∫squeda exacta completada: {type(contexto)}")
                
                if contexto and contexto.get("pageContent"):
                    print(f"‚úÖ Art√≠culo {numero_articulo} encontrado por b√∫squeda exacta")
                else:
                    print(f"‚ùå Art√≠culo {numero_articulo} no encontrado, intentando b√∫squeda sem√°ntica")
                    contexto = None
                    
            except Exception as e:
                print(f"üö® ERROR en buscar_articulo_por_numero: {str(e)}")
                contexto = None
        
        # B√öSQUEDA SEM√ÅNTICA CON MANEJO DE ERRORES
        if not contexto or not contexto.get("pageContent"):
            print("üîé Iniciando b√∫squeda sem√°ntica...")
            
            if OPENAI_AVAILABLE:
                try:
                    # EMBEDDING CON TIMEOUT Y MANEJO DE ERRORES
                    print("üî¢ Generando embedding...")
                    embedding_response = openai_client.embeddings.create(
                        model="text-embedding-ada-002",
                        input=pregunta_actual[:500],  # Limitar entrada
                        timeout=10  # Timeout de 10 segundos
                    )
                    query_vector = embedding_response.data[0].embedding
                    print(f"‚úÖ Embedding generado: {len(query_vector)} dimensiones")
                    
                    # B√öSQUEDA VECTORIAL CON TIMEOUT
                    print("üóÑÔ∏è Buscando en Qdrant...")
                    contexto = buscar_articulo_relevante(query_vector, collection_name)
                    print(f"‚úÖ B√∫squeda Qdrant completada: {type(contexto)}")
                    
                    if contexto and contexto.get("pageContent"):
                        print("‚úÖ Contexto encontrado por b√∫squeda sem√°ntica")
                    else:
                        print("‚ùå No se encontr√≥ contexto en b√∫squeda sem√°ntica")
                        
                except Exception as e:
                    print(f"üö® ERROR en b√∫squeda sem√°ntica: {str(e)}")
                    contexto = None
            else:
                print("‚ö†Ô∏è OpenAI no disponible para embeddings")
                
    except Exception as e:
        print(f"üö® ERROR GENERAL en b√∫squeda: {type(e).__name__}: {str(e)}")
        contexto = None
    
    return contexto

def generar_respuesta_legal(historial: List[MensajeChat], contexto: Optional[Dict] = None) -> str:
    """
    FIX: Generaci√≥n con l√≠mites estrictos para evitar error 422
    """
    if not OPENAI_AVAILABLE or not openai_client:
        return generar_respuesta_con_contexto(historial[-1].content, contexto)
    
    try:
        print("üí≠ INICIO generar_respuesta_legal")
        print(f"üìä Historial: {len(historial)} mensajes")
        print(f"üìñ Contexto disponible: {bool(contexto and contexto.get('pageContent'))}")
        
        # L√çMITES ESTRICTOS PARA EVITAR ERROR 422
        mensajes = [{"role": "system", "content": INSTRUCCION_SISTEMA_LEGAL[:1000]}]  # Limitar instrucciones
        
        # MANEJO MEJORADO DEL CONTEXTO
        if contexto and contexto.get("pageContent"):
            contexto_limitado = contexto.get('pageContent', '')[:1500]  # L√≠mite estricto
            prompt_limitado = construir_prompt(contexto_limitado, historial[-1].content[:300])
            
            # LIMITAR PROMPT TOTAL
            if len(prompt_limitado) > 2000:
                prompt_limitado = prompt_limitado[:2000] + "..."
            
            mensajes.append({"role": "user", "content": prompt_limitado})
            print(f"üìñ Prompt construido: {len(prompt_limitado)} chars")
        else:
            # SIN CONTEXTO: Solo pregunta actual limitada
            pregunta_limitada = historial[-1].content[:300]
            mensajes.append({"role": "user", "content": pregunta_limitada})
            print(f"üìù Pregunta sin contexto: {len(pregunta_limitada)} chars")
        
        print("üîó Llamando a OpenAI con l√≠mites estrictos...")
        
        # LLAMADA CON PAR√ÅMETROS ULTRA-CONSERVADORES
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",  # Modelo m√°s r√°pido y econ√≥mico
            messages=mensajes,
            temperature=0.1,
            max_tokens=800,  # L√≠mite reducido
            timeout=20,  # Timeout de 20 segundos
            presence_penalty=0,
            frequency_penalty=0
        )
        
        respuesta = response.choices[0].message.content
        print(f"‚úÖ Respuesta generada: {len(respuesta)} chars")
        
        return respuesta
        
    except Exception as e:
        print(f"üö® ERROR en generar_respuesta_legal: {type(e).__name__}: {str(e)}")
        print("üîÑ Usando respuesta con contexto como fallback")
        return generar_respuesta_con_contexto(historial[-1].content, contexto)

def generar_respuesta_con_contexto(pregunta: str, contexto: Optional[Dict] = None) -> str:
    """
    Respuesta directa usando el contexto de Qdrant cuando OpenAI no est√° disponible
    """
    if contexto and contexto.get("pageContent"):
        # Usar el prompt_builder para consistencia
        contexto_legal_texto = contexto.get('pageContent', '')
        prompt_construido = construir_prompt(contexto_legal_texto, pregunta)
        
        # Respuesta b√°sica usando el contexto
        ley = contexto.get('nombre_ley', 'Legislaci√≥n paraguaya')
        articulo = contexto.get('numero_articulo', 'N/A')
        contenido = contexto.get('pageContent', '')
        
        response = f"""**{ley} - Art√≠culo {articulo}**

{contenido}

---

**Aplicaci√≥n a su consulta:**
Esta disposici√≥n legal responde a su pregunta sobre "{pregunta}".

**Nota importante:** Para asesoramiento espec√≠fico sobre su situaci√≥n particular, consulte con un abogado especializado.

*Fuente: {ley}, Art√≠culo {articulo}*"""
        
        logger.info(f"‚úÖ Respuesta generada con contexto: {ley} Art. {articulo}")
        return response
    else:
        return f"""**Consulta Legal**

No encontr√© esa disposici√≥n espec√≠fica en mi base de datos legal para: "{pregunta}"

**Sugerencias:**
1. **Reformule su consulta** con t√©rminos m√°s espec√≠ficos
2. **Mencione el c√≥digo o ley** espec√≠fica si la conoce  
3. **Use n√∫meros de art√≠culo** si busca disposiciones particulares

**Consultas que puedo resolver:**
- Art√≠culos espec√≠ficos por n√∫mero (ej: "art√≠culo 95 del c√≥digo aduanero")
- Temas generales (ej: "violencia dom√©stica", "derechos laborales")
- Procedimientos legales (ej: "c√≥mo hacer una denuncia")

Para asesoramiento personalizado, consulte siempre con un abogado especializado.

*¬øPuede reformular su consulta con m√°s detalles espec√≠ficos?*"""

def extraer_fuente_legal(contexto: Optional[Dict]) -> Optional[FuenteLegal]:
    """
    Extrae informaci√≥n de la fuente legal del contexto
    """
    if not contexto:
        return None
    
    return FuenteLegal(
        ley=contexto.get("nombre_ley", "No especificada"),
        articulo_numero=str(contexto.get("numero_articulo", "N/A")),
        libro=contexto.get("libro"),
        titulo=contexto.get("titulo")
    )

# === MIDDLEWARE ===
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    client_ip = request.client.host
    logger.info(f"üì• {request.method} {request.url.path} - IP: {client_ip}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(f"üì§ {response.status_code} - {process_time:.2f}s")
    
    return response

# === ENDPOINTS ===
@app.get("/", response_model=StatusResponse)
async def sistema_status():
    """Estado del sistema COLEPA"""
    return StatusResponse(
        status="‚úÖ Sistema COLEPA Operativo",
        timestamp=datetime.now(),
        version="3.1.0",
        servicios={
            "openai": "disponible" if OPENAI_AVAILABLE else "no disponible",
            "busqueda_vectorial": "disponible" if VECTOR_SEARCH_AVAILABLE else "modo_demo",
            "base_legal": "legislaci√≥n paraguaya completa"
        },
        colecciones_disponibles=len(MAPA_COLECCIONES)
    )

@app.get("/api/health")
async def health_check():
    """Verificaci√≥n de salud detallada"""
    health_status = {
        "sistema": "operativo",
        "timestamp": datetime.now().isoformat(),
        "version": "3.1.0",
        "servicios": {
            "openai": "‚ùå no disponible",
            "qdrant": "‚ùå no disponible" if not VECTOR_SEARCH_AVAILABLE else "‚úÖ operativo",
            "base_legal": "‚úÖ cargada"
        }
    }
    
    if OPENAI_AVAILABLE and openai_client:
        try:
            # Test m√≠nimo de OpenAI
            openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            health_status["servicios"]["openai"] = "‚úÖ operativo"
        except Exception as e:
            health_status["servicios"]["openai"] = f"‚ùå error: {str(e)[:50]}"
    
    return health_status

@app.get("/api/test-openai")
async def test_openai_connection():
    """
    Endpoint para probar conexi√≥n OpenAI espec√≠ficamente
    """
    if not OPENAI_AVAILABLE:
        return {"status": "ERROR", "message": "OpenAI no configurado"}
    
    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5,
            timeout=10
        )
        
        return {
            "status": "OK",
            "message": "OpenAI operativo",
            "model": "gpt-3.5-turbo",
            "response": response.choices[0].message.content
        }
        
    except Exception as e:
        return {
            "status": "ERROR", 
            "message": f"OpenAI error: {str(e)}",
            "error_type": type(e).__name__
        }

@app.get("/api/codigos")
async def listar_codigos_legales():
    """Lista todos los c√≥digos legales disponibles"""
    return {
        "codigos_disponibles": list(MAPA_COLECCIONES.keys()),
        "total_codigos": len(MAPA_COLECCIONES),
        "descripcion": "C√≥digos legales completos de la Rep√∫blica del Paraguay",
        "ultima_actualizacion": "2024",
        "cobertura": "Legislaci√≥n nacional vigente"
    }

# ========== ENDPOINT PRINCIPAL MODIFICADO ==========
@app.post("/api/consulta", response_model=ConsultaResponse)
async def procesar_consulta_legal(
    request: ConsultaRequest, 
    background_tasks: BackgroundTasks
):
    """
    Endpoint principal - CON LOGGING DIAGN√ìSTICO COMPLETO
    """
    start_time = time.time()
    
    try:
        print(f"üöÄ INICIO ENDPOINT - Nueva consulta recibida")
        print(f"üìä Request: {len(request.historial)} mensajes en historial")
        
        historial = request.historial
        pregunta_actual = historial[-1].content
        print(f"üìù Pregunta actual: {pregunta_actual[:100]}...")
        
        # L√çMITE DE HISTORIAL PARA EVITAR ERROR 422
        MAX_HISTORIAL = 3  # MUY CONSERVADOR
        if len(historial) > MAX_HISTORIAL:
            historial_limitado = historial[-MAX_HISTORIAL:]
            print(f"‚ö†Ô∏è Historial limitado: {len(historial)} ‚Üí {len(historial_limitado)} mensajes")
        else:
            historial_limitado = historial
        
        # CLASIFICACI√ìN INTELIGENTE CON LOGGING
        if CLASIFICADOR_AVAILABLE:
            print("üß† Iniciando clasificaci√≥n inteligente...")
            try:
                clasificacion = clasificar_y_procesar(pregunta_actual)
                print(f"‚úÖ Clasificaci√≥n completada: {clasificacion.get('tipo_consulta', 'N/A')}")
                
                # MANEJO DE CONSULTAS CONVERSACIONALES
                if clasificacion['es_conversacional'] and clasificacion['respuesta_directa']:
                    print("üí¨ Generando respuesta conversacional...")
                    return ConsultaResponse(
                        respuesta=clasificacion['respuesta_directa'],
                        fuente=None,
                        recomendaciones=None,
                        tiempo_procesamiento=round(time.time() - start_time, 2),
                        es_respuesta_oficial=True
                    )
                
                if not clasificacion['requiere_busqueda']:
                    print("üö´ Consulta no legal, redirigiendo...")
                    return ConsultaResponse(
                        respuesta="Me especializo √∫nicamente en consultas legales paraguayas. ¬øHay alguna pregunta legal espec√≠fica en la que pueda ayudarte?",
                        fuente=None,
                        recomendaciones=None,
                        tiempo_procesamiento=round(time.time() - start_time, 2),
                        es_respuesta_oficial=True
                    )
                
                print("üîç Consulta legal confirmada, procediendo...")
                
            except Exception as e:
                print(f"üö® ERROR en clasificaci√≥n: {str(e)}")
                print("üîÑ Continuando sin clasificaci√≥n...")
        
        # CLASIFICACI√ìN DEL C√ìDIGO LEGAL
        print("üìö Iniciando clasificaci√≥n de c√≥digo legal...")
        try:
            collection_name = clasificar_consulta_con_ia_robusta(pregunta_actual)
            print(f"‚úÖ C√≥digo identificado: {collection_name}")
        except Exception as e:
            print(f"üö® ERROR en clasificaci√≥n de c√≥digo: {str(e)}")
            collection_name = "colepa_civil_maestro"  # Fallback seguro
            print(f"üîÑ Usando fallback: {collection_name}")
        
        # EXTRACCI√ìN DE N√öMERO DE ART√çCULO
        numero_articulo = extraer_numero_articulo_mejorado(pregunta_actual)
        print(f"üî¢ N√∫mero de art√≠culo extra√≠do: {numero_articulo}")
        
        # B√öSQUEDA CON MANEJO DE ERRORES
        contexto = None
        if VECTOR_SEARCH_AVAILABLE:
            print("üîé Iniciando b√∫squeda vectorial...")
            try:
                contexto = await buscar_con_manejo_errores(numero_articulo, pregunta_actual, collection_name)
                print(f"‚úÖ B√∫squeda completada: {bool(contexto and contexto.get('pageContent'))}")
            except Exception as e:
                print(f"üö® ERROR en b√∫squeda: {str(e)}")
                contexto = None
        else:
            print("‚ö†Ô∏è B√∫squeda vectorial no disponible")
        
        # GENERACI√ìN DE RESPUESTA
        print("üí≠ Iniciando generaci√≥n de respuesta...")
        try:
            respuesta = generar_respuesta_legal(historial_limitado, contexto)
            print(f"‚úÖ Respuesta generada: {len(respuesta)} chars")
        except Exception as e:
            print(f"üö® ERROR en generaci√≥n: {str(e)}")
            respuesta = "Lo siento, no pude procesar tu consulta en este momento. Por favor, intenta reformular tu pregunta."
        
        # PREPARAR RESPUESTA FINAL
        tiempo_procesamiento = time.time() - start_time
        fuente = extraer_fuente_legal(contexto)
        
        response_data = ConsultaResponse(
            respuesta=respuesta,
            fuente=fuente,
            recomendaciones=None,
            tiempo_procesamiento=round(tiempo_procesamiento, 2),
            es_respuesta_oficial=True
        )
        
        print(f"üéâ Consulta procesada exitosamente en {tiempo_procesamiento:.2f}s")
        return response_data
        
    except Exception as e:
        print(f"üö® ERROR CR√çTICO EN ENDPOINT: {type(e).__name__}: {str(e)}")
        print(f"üö® L√≠nea de error: {e.__traceback__.tb_lineno if e.__traceback__ else 'N/A'}")
        
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Error interno del sistema",
                "mensaje": "No fue posible procesar su consulta",
                "codigo_error": f"{type(e).__name__}: {str(e)[:100]}"
            }
        )

# === MANEJO DE ERRORES ===
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": True,
            "status_code": exc.status_code,
            "detalle": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "mensaje_usuario": "Ha ocurrido un error procesando su consulta"
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"‚ùå Error no controlado: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": True,
            "status_code": 500,
            "detalle": "Error interno del servidor",
            "timestamp": datetime.now().isoformat(),
            "mensaje_usuario": "El sistema est√° experimentando dificultades t√©cnicas"
        }
    )

# === PUNTO DE ENTRADA ===
if __name__ == "__main__":
    logger.info("üöÄ Iniciando COLEPA - Sistema Legal Gubernamental v3.1.0")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=int(os.getenv("PORT", 8000)),
        reload=False,  # Deshabilitado en producci√≥n
        log_level="info"
    )
